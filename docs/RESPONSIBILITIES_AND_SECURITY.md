# ğŸ›¡ï¸ Responsibilities & Security

> Your accountability as a developer using AI assistance â€“ security safeguards and best practices.

**Audience:** All developers using AI assistance | **Prerequisites:** None



## AI-Slop


> ğŸš¨ **Golden Rule:** AI is a co-pilot, not an autopilot. You are responsible for code quality, security, and compliance.

âš¡ **Blindly accepting AI-generated code feels fast.** You save 5 minutes writing code or reviewing a PR. Then you lose those 5 minutesâ€”**and much more**â€”later when bugs surface and technical debt accumulates:

### Timeline: What "Saving Time" Really Costs

| Time | Event | Impact |
|------|-------|--------|
| T+0min | âœ… AI generates code in seconds | Feels productive |
| T+5min | ğŸš€ You commit without reading it | No review friction |
| T+1hr | ğŸ‘€ Code review: "What is this doing?" | Questions arise |
| T+2hr | ğŸ˜… Revert, rewrite, re-review | The real cost begins |
| T+3hr | ğŸ› Bug appears in production | Users report issues |
| T+1week | ğŸ› ï¸ Technical debt backlog grows | More rework needed |
| T+6months | ğŸ’¸ "Why is everything so slow?" | Systemic slowdown |

**ğŸ“Š Total cost: 1000x the 5 minutes you "saved"**

---

### The Compound Interest Problem

| Aspect | âŒ Skip Review | âœ… Review Properly |
|--------|-----------|-----------------|
| **Time Saved** | 5 min | 3 min |
| **Technical Debt** | âˆ | Low |
| **Review Cycles** | +10min | None |
| **Prod Bugs** | +2 hours | None |
| **Refactoring** | +1 week | Minimal |
| **ROI** | **Negative** | **+200%** |

### Common "Slop" Patterns to Catch

AI-generated code often exhibits predictable weaknesses. These **code smells** indicate problems that require deeper investigation:

#### ğŸ”´ Critical (Security & Data Loss)

| Pattern | Red Flag | Why It Matters |
|---------|----------|---|
| ğŸ›¡ï¸ **Exposed internals** | Raw objects passed to external layers | Security & API brittleness |
| âœ… **Missing validation** | Accepts user input without checking | Injection attacks, data corruption |
| ğŸš¨ **Silent data loss** | Catches errors without logging/rethrowing | Bugs disappear into void |

#### ğŸŸ  High (Performance & Stability)

| Pattern | Red Flag | Why It Matters |
|---------|----------|---|
| âš¡ **N+1 queries** | Database calls inside loops | Terrible performance at scale |
| ğŸ’¥ **Missing error handling** | No try/catch, null checks, or fallbacks | Silent failures in production |
| ğŸ¯ **Implicit assumptions** | Assumes happy path, ignores edge cases | Crashes on unexpected input |

#### ğŸŸ¡ Medium (Maintainability & Testing)

| Pattern | Red Flag | Why It Matters |
|---------|----------|---|
| ğŸ”¢ **Magic numbers & strings** | Hardcoded values scattered throughout | Impossible to maintain |
| ğŸ“‹ **Duplicated logic** | Similar code in multiple places | Inconsistencies when fixing bugs |
| ğŸª **God objects** | Huge functions/classes doing everything | Unmaintainable, impossible to test |
| ğŸ“¦ **Too many parameters** | Functions with 5+ arguments | Hard to test, easy to confuse |

### The Bottom Line

> Reviewing AI code takes **20%** of the time you'd save by skipping review.
> Skipping review costs you **1000%** in technical debt.

The productivity gain is realâ€”**but only if you do the work right.**



## What & Why


AI boosts productivityâ€”but only with discipline. Every AI suggestion passes through **human checkpoints**, especially for security, complexity, and architecture. This project demonstrates a workflow where **you make the calls** and AI handles the grunt work.

### The Human-in-the-Loop Workflow

```
YOU PLAN          YOU CONFIRM      YOU REVIEW       YOU APPROVE
   â†“                 â†“                â†“                â†“
@Specify â†’ [âœ… You] â†’ @Implement â†’ [âœ… You] â†’ @Test â†’ [âœ… You] â†’ Merge
   
Key: AI generates ideas. You decide what ships.
```

**Critical approval points (all require human sign-off):**
- âœ… **Specification** â€“ Scope & acceptance criteria
- âœ… **Implementation** â€“ Each code change confirmed
- âœ… **Testing** â€“ Results validated, edge cases checked
- âœ… **Merge** â€“ Final review before production

This isn't "let AI do the work." It's "let AI do the repetitive work while you focus on quality, security, and decision-making."



## Data Privacy

### Use Enterprise Tiers

| Service | Data Used for Training? | Recommendation |
|---------|-------------------------|----------------|
| GitHub Copilot (Business) | No | âœ… Recommended |
| Anthropic (Enterprise) | No | âœ… Best for sensitive code |
| Claude.ai (Free) | May be | âš ï¸ Avoid for proprietary code |
| Free tier services | Unclear | âš ï¸ Avoid for proprietary code |

### Data Flow Awareness

```
Your Code â†’ MCP Server â†’ External Service â†’ AI Model
```

Always:
- Use `.env` for secrets, never commit
- Use `.gitignore` to exclude sensitive files
- Use local MCP servers when possible

## MCP Security Risks

**New to MCP?** The [Model Context Protocol][mcp-docs] allows AI agents to access external tools and data. Learn how [this project uses MCP][mcp-integrations] and understand the security implications when you grant agents permissions. 

### 1. ğŸ”“ Confused Deputy Problem

| Aspect | Details |
|--------|---------|
| **Risk** | Agent combines permissions in unintended ways |
| **Example** | Agent has read code + write to Jira â†’ reads secrets, posts to public Jira |
| **Prevention** | Minimal permissions per custom agent and server, separate read-only & write access |

### 2. ğŸ”‘ Credential Exposure

| Aspect | Details |
|--------|---------|
| **Risk** | API keys logged or exposed in output/errors |
| **âŒ Bad** | `console.log(\`Token: ${apiToken}\`)` |
| **âœ… Good** | `console.log(\`Token: ${apiToken.slice(0, 4)}...\`)` |

### 3. ğŸ¯ Agent Tool Overreach

| Agent | Can Access | Cannot Access |
|-------|------------|---------------|
| @Specify | Read code, Jira/Figma (read-only) | Write files, execute code |
| @Implement | Create/edit files, dev execution | Prod database, delete without confirm |
| @Test | Edit test files, run tests | Prod code, infrastructure |


## AI-Assisted Version Control

Copilot provides built-in features for version control tasks. Use them, but review the output.

### Available Features

| Feature | Access | Review Requirement |
|---------|--------|-------------------|
| **Commit Messages** | Sparkle icon in Source Control | âœ… Review before commit |
| **PR Descriptions** | GitHub PR extension | âœ… Review before opening |
| **Merge Conflict Resolution** | "Resolve with AI" button | âš ï¸ **Careful review** required |
| **Code Review** | Right-click â†’ Review | Use as input, not final answer |

### ğŸ’¬ Commit Message Generation

The AI summarizes staged changes into a commit message. **You decide if it's accurate.**

#### Workflow Comparison

| Step | âœ… Good Workflow | âš ï¸ Bad Workflow |
|------|-----------------|-----------------|
| 1 | Stage changes | Stage changes |
| 2 | Click sparkle â†’ Generate message | Click sparkle â†’ Generate message |
| 3 | **Read & edit** the message | Accept blindly |
| 4 | Commit | Commit |

#### Verification Checklist

Before committing an AI-generated message:
- [ ] ğŸ“ Message accurately describes all changes
- [ ] ğŸ”’ No sensitive information included
- [ ] ğŸ“‹ Follows project conventions (if any)

### Merge Conflict Resolution

> âš ï¸ **High risk.** AI may choose the wrong resolution.

```
Conflict: Both branches modified the same function

AI suggestion: Keep branch A changes
Reality: Branch B has the critical fix

â†’ Always verify merge resolutions line-by-line
```

**When to use AI for conflicts:**
- Simple text conflicts (documentation, comments)
- Obvious additions (new imports, new functions)

**When to resolve manually:**
- Logic changes in the same function
- Security-related code
- Complex refactors


## When to Use AI vs. Manual

| Task Category | âœ… AI Excels | âš ï¸ You Handle |
|---|---|---|
| **Boilerplate** | Following conventions | âŒ Never skip |
| **Testing** | Scaffolding, setup | Security-critical tests |
| **Refactoring** | Within patterns | Novel architecture |
| **Docs** | Initial drafts, formatting | Security docs |
| **Features** | Initial drafts | Complex logic, auth, encryption |

**Golden Rule:** If it involves security, novel decisions, or your domain's core logicâ€”you write it.

## Incident Response

### ğŸš¨ Agent Misbehavior

| Step | Action | Details |
|------|--------|---------|
| 1ï¸âƒ£ | ğŸ›‘ **Disable** | Remove tool access immediately |
| 2ï¸âƒ£ | ğŸ‘€ **Review** | Examine what happened & root cause |
| 3ï¸âƒ£ | ğŸ”§ **Fix** | Update agent constraints/permissions |
| 4ï¸âƒ£ | âœ… **Test** | Verify constraints work before re-enabling |


## ğŸ”’ Pre-Deployment Security Checklist

Before shipping AI-assisted code:

| Category | Checklist Item | Why? |
|----------|---|---|
| ğŸ” **Secrets** | No hardcoded credentials, all in `.env` | Prevents credential leaks |
| ğŸ‘¥ **Agents** | Minimal permissions, combinations reviewed | Limits attack surface |
| ğŸ“¡ **MCP** | Isolated environments, data flow understood | Prevents confused deputy |
| ğŸ“ **Code** | Manually reviewed, tests passing | Catches AI slop & bugs |
| ğŸ“Š **Data** | No sensitive data in logs, compliance met | GDPR/privacy requirements |


## Related

- [Custom Agents][custom-agents] â€“ Agent tool restrictions
- [MCP Integrations][mcp-integrations] â€“ Server security details
- [GitHub Copilot Trust][copilot-trust]

<!-- Reference Links -->
[custom-agents]: ./CUSTOM_AGENTS.md
[mcp-integrations]: ./MCP.md
[mcp-docs]: https://modelcontextprotocol.io/
[copilot-trust]: https://copilot.github.trust.page/
